# ==================================================
# OllamaBench Configuration
# ==================================================

# --- Core Models ---
JUDGE_MODEL: "llama3.1:8b"

# --- Prompt & Data Configuration ---
LOAD_MULTIPLE_DATASETS: true

PROMPT_DATASET: "livebench/data_analysis"

PROMPT_DATASETS:
  - livebench/math
  - livebench/data_analysis
  - livebench/language
  - livebench/instruction_following
  - livebench/coding
  
PROMPT_DATASET_COLUMN: "turns"
GROUND_TRUTH_DATASET_COLUMN: "ground_truth"
PROMPT_DATASET_CATEGORY_COLUMN: "category"
CURRENT_CATEGORY: "math"

# --- Local Data Storage ---
paths:
  data_dir: "data"
  results_file: "./data/results.json"
  lock_file: "./data/results.lock"
  dataset_category_dir: "./data/categories"
  dataset_file_suffix: "_prompts.json"
  dataset_save_lock_file: "./data/prompt_dataset.lock"
  log_file: "./data/ollama_bench.log"

NUM_SAVE_DATASET_ENTRIES: 200 

# --- ELO Rating Configuration ---
elo:
  initial_rating: 1000.0
  k_factor: 32

# --- Comparison & Evaluation Cycle ---
comparison:
  comparisons_per_run: 1 

# --- Ollama API Configuration ---
ollama:
  api_base_url: "http://localhost:11434"
  chat_api_path: "/api/chat"
  tags_api_path: "/api/tags"
  default_timeout: 120 
  max_retries: 3
  retry_delay: 5


generation_options:
  temperature: 0.7
  top_p: 0.9
  top_k: 40

# --- Dashboard Configuration ---
dashboard:
  host: "0.0.0.0" 
  port: 5001     
  debug: false    
  refresh_interval_seconds: 30

# --- Logging Configuration ---
logging:
  level: "INFO" 
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
