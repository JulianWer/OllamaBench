# ==================================================
# OllamaBench Configuration
# ==================================================


categories: ['schreiben','rollenspiel','begr√ºndung', 'extraktion','stamm','geisteswissenschaften']

comparison:
  comparisons_per_prompt: 35

# --- Model Config ---
comparison_llms:
  names: ['gemma3:4b','gemma3:1b','gemma2:2b', 'gemma:2b-instruct',
                    'qwen3:4b','qwen3:1.7b','qwen3:0.6b','qwen3:8b' ,'qwen:7b-chat'
                    ,'llama3.2:3b', 'llama3.2:1b', 'llama3.1:8b', 'mistral:7b','Ministral-8B-Instruct-2410-Q4_K_M:latest']
  has_reasoning: true
  generation_options:
    temperature: 0.0

judge_llm:
  name: 'qwen3:30b-a3b' # change this for a different judge model
  has_reasoning: false
  generation_options:
    temperature: 0.0
  system_prompt: "You are an automated evaluation system. Your SOLE task is to determine which AI assistant's response is better based on the user's query and potentially a ground truth answer. 
                  \n**Evaluation Criteria:**
                  * Helpfulness and relevance to the user's query.
                  * Accuracy and correctness of information.
                  * Depth, detail, and creativity.
                  * Adherence to instructions in the user query."

  
# --- Dataset ---  
dataset:
  name: "VAGOsolutions/MT-Bench-TrueGerman" #"HuggingFaceH4/mt_bench_prompts" # default dataset if no data exists localy 
  data_files:
    train: "question_de.jsonl" # specific for MT-Bench-TrueGerman 
  columns:
    prompt: "turns"
    ground_truth: "reference"
    category: "category"
    id: "question_id"


# --- Local Data Storage ---
paths:
  data_dir: "data"
  results_file: "./data/results.json"
  lock_file: "./data/results.lock"
  output_dir: "./data/model_responses"
  dataset_category_dir: "./data/categories"
  dataset_file_suffix: "_prompts.json"
  dataset_save_lock_file: "./data/prompt_dataset.lock"

NUM_SAVE_DATASET_ENTRIES: 1000 

# --- ELO Rating Configuration ---

used_rating_method: mElo # mElo or elo

elo:
  initial_rating: 1000
  k_factor: 16

mELO:
  initial_rating: 1000
  learning_rate: 100
  epochs: 300


# --- API Configuration ---
LLM_runtime:
  api_base_url: "http://localhost:11434"
  chat_api_path: "/api/chat"
  tags_api_path: "/api/tags"
  default_timeout: 300 
  max_retries: 3
  retry_delay: 5

# --- Dashboard Configuration ---
dashboard:
  host: "127.0.0.1" 
  port: 5001     
  debug: false    
  refresh_interval_seconds: 30

# --- Logging Configuration ---
logging:
  level: "INFO" 
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
